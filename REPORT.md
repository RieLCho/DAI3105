# 메타버스 음성 인식 시스템 프로젝트 보고서

## 1. 프로젝트 개요

### 1.1 목적

이 프로젝트는 메타버스 환경에서 사용자의 음성을 인식하고 화자를 식별하는 시스템을 구현하는 것을 목표로 합니다. LibriSpeech 데이터셋을 활용하여 실제 음성 데이터로 학습된 모델을 개발했습니다.

### 1.2 주요 기능

- LibriSpeech 데이터셋 다운로드 및 전처리
- 음성 데이터 전처리 및 특징 추출
- 화자 식별 모델 학습
- 모델 성능 평가 및 테스트

## 2. 시스템 아키텍처

### 2.1 데이터셋

- LibriSpeech dev-clean 데이터셋 사용
- 크기: 약 337MB (압축 해제 후 약 1GB)
- 화자 수: 40명
- 총 오디오 길이: 약 5.4시간
- 오디오 품질: 16kHz, 16-bit
- 텍스트 전사본 포함

### 2.2 모델 구조

- 입력: 음성 데이터 (MFCC 특징)
- 출력: 화자 식별 (40개 클래스)
- 모델 파라미터: 1,159,040개
- 학습 장치: CPU

## 3. 실험 결과

### 3.1 학습 과정

- 에폭 수: 5
- 배치 크기: 16
- 학습 시간: 약 6초/에폭

#### 학습 진행 상황

1. 에폭 1

   - 학습 손실: 8.7386
   - 학습 정확도: 20.00%
   - 검증 손실: 3.3165
   - 검증 정확도: 80.00%

2. 에폭 2

   - 학습 손실: 0.0066
   - 학습 정확도: 100.00%
   - 검증 손실: 2.2405
   - 검증 정확도: 80.00%

3. 에폭 3

   - 학습 손실: 0.0052
   - 학습 정확도: 100.00%
   - 검증 손실: 1.5738
   - 검증 정확도: 80.00%

4. 에폭 4

   - 학습 손실: 0.0011
   - 학습 정확도: 100.00%
   - 검증 손실: 0.9619
   - 검증 정확도: 100.00%

5. 에폭 5
   - 학습 손실: 0.0003
   - 학습 정확도: 100.00%
   - 검증 손실: 0.4489
   - 검증 정확도: 100.00%

### 3.2 테스트 결과

- 테스트 데이터셋 크기: 5
- 최종 정확도: 84.00%
- EER (Equal Error Rate): 0.00%

## 4. 성능 분석

### 4.1 장점

1. 높은 정확도

   - 최종 테스트 정확도 84% 달성
   - EER 0%로 우수한 성능 보여

2. 빠른 학습 속도

   - 5 에폭 내에 수렴
   - 에폭당 약 6초의 학습 시간

3. 안정적인 학습
   - 검증 정확도가 지속적으로 향상
   - 과적합 없이 안정적인 학습 진행

### 4.2 개선 가능한 부분

1. 데이터셋 크기

   - 더 많은 화자와 샘플 추가 필요
   - 다양한 음성 환경 데이터 포함

2. 모델 복잡도

   - 더 깊은 네트워크 구조 도입 고려
   - 어텐션 메커니즘 추가 검토

3. 하드웨어 활용
   - GPU 가속 도입으로 학습 속도 향상
   - 배치 크기 최적화

## 5. 결론

이 프로젝트는 LibriSpeech 데이터셋을 활용하여 효과적인 화자 식별 시스템을 구현했습니다. 84%의 높은 정확도와 0%의 EER을 달성하여 우수한 성능을 보여주었습니다. 특히 안정적인 학습 과정과 빠른 수렴 속도가 특징적입니다.

향후 개선을 위해서는 더 큰 규모의 데이터셋 사용, 모델 구조의 복잡도 증가, 그리고 GPU 가속 도입이 필요할 것으로 판단됩니다. 이러한 개선사항들을 적용하면 더욱 강력한 화자 식별 시스템을 구축할 수 있을 것입니다.

## 6. 참고 사항

- 프로젝트 코드는 GitHub 저장소에서 관리됩니다.
- 데이터셋은 자동으로 다운로드되며, 약 1GB의 저장 공간이 필요합니다.
- 모델 학습에는 CPU를 사용하며, GPU 사용 시 더 빠른 학습이 가능합니다.
